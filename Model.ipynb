{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install path\n",
    "%pip install opencv-python\n",
    "%pip install --upgrade pyqt5 lxml"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image labelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "!labelme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "labelimg_path = os.path.abspath(os.path.join(\"Tensorflow\", \"labelimg\"))\n",
    "\n",
    "!cd {labelimg_path} && pyrcc5 -o libs/resources.py resources.qrc\n",
    "!cd {labelimg_path} && python labelImg.py"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from main import files, paths\n",
    "import os\n",
    "\n",
    "images_dir = os.path.join(paths[\"IMAGE_PATH\"], \"train\")\n",
    "out_dir = os.path.join(paths[\"IMAGE_PATH\"], \"augmented\")\n",
    "\n",
    "cmd = f\"\"\"python {files[\"DATA_AUGM_SCRIPT\"]} \n",
    "        --images_dir=\"{images_dir}\"\n",
    "        --out_dir=\"{out_dir}\"\n",
    "    \"\"\"\n",
    "\n",
    "cmd = \" \".join([s.strip() for s in str(cmd).split()])\n",
    "\n",
    "\n",
    "print(cmd)\n",
    "\n",
    "# !{cmd}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate JSON files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from main import paths\n",
    "\n",
    "images_path = paths[\"IMAGE_PATH\"]\n",
    "annotation_path = paths[\"ANNOTATION_PATH\"]\n",
    "\n",
    "train_img_dir = os.path.join(images_path, \"train\")\n",
    "val_img_dir = os.path.join(images_path, \"val\")\n",
    "\n",
    "train_json_file = os.path.join(train_img_dir, \"train.json\")\n",
    "val_json_file = os.path.join(val_img_dir, \"val.json\")\n",
    "\n",
    "if(os.path.exists(train_json_file)):\n",
    "    os.remove(train_json_file)\n",
    "\n",
    "if(os.path.exists(val_json_file)):\n",
    "    os.remove(val_json_file)\n",
    "\n",
    "train_cmd = f\"\"\"python src/labelme2coco.py \"{train_img_dir}\"\n",
    "    --output=\"{train_json_file}\"\n",
    "    \"\"\"\n",
    "\n",
    "train_cmd = \" \".join([s.strip() for s in str(train_cmd).split()])\n",
    "\n",
    "print(train_cmd)\n",
    "!{train_cmd}\n",
    "\n",
    "val_cmd = f\"\"\"python src/labelme2coco.py \"{val_img_dir}\"\n",
    "    --output=\"{val_json_file}\"\n",
    "    \"\"\"\n",
    "\n",
    "val_cmd = \" \".join([s.strip() for s in str(val_cmd).split()])\n",
    "\n",
    "print(val_cmd)\n",
    "!{val_cmd}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate TFRecord files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from main import paths\n",
    "\n",
    "images_path = paths[\"IMAGE_PATH\"]\n",
    "annotation_path = paths[\"ANNOTATION_PATH\"]\n",
    "\n",
    "train_img_dir = os.path.join(images_path, \"train\")\n",
    "val_img_dir = os.path.join(images_path, \"val\")\n",
    "\n",
    "train_json_file = os.path.join(train_img_dir, \"train.json\")\n",
    "val_json_file = os.path.join(val_img_dir, \"val.json\")\n",
    "\n",
    "tf_record_Cmd = f\"\"\"python src/create_coco_tf_record.py \n",
    "                --logtostderr\n",
    "                --train_image_dir=\"{os.path.abspath(os.path.join(images_path, \"train\"))}\"\n",
    "                --val_image_dir=\"{os.path.abspath(os.path.join(images_path, \"val\"))}\"\n",
    "                --train_annotations_file=\"{train_json_file}\"\n",
    "                --val_annotations_file=\"{val_json_file}\"\n",
    "                --include_masks={True}\n",
    "                --output_dir=\"{annotation_path}\"\n",
    "                \"\"\"\n",
    "tf_record_Cmd = \" \".join([s.strip() for s in str(tf_record_Cmd).split()])\n",
    "\n",
    "print(tf_record_Cmd)\n",
    "!{tf_record_Cmd}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully created the TFRecord file: c:\\Users\\jtorn\\Desktop\\Dev\\Redes neuronales e AI\\ray_c\\Tensorflow\\workspace\\annotations\\train.record\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jtorn\\miniconda3\\envs\\ray_c\\lib\\site-packages\\google\\auth\\crypt\\_cryptography_rsa.py:22: CryptographyDeprecationWarning: Python 3.6 is no longer supported by the Python core team. Therefore, support for it is deprecated in cryptography. The next release of cryptography (40.0) will be the last to support Python 3.6.\n",
      "  import cryptography.exceptions\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully created the TFRecord file: c:\\Users\\jtorn\\Desktop\\Dev\\Redes neuronales e AI\\ray_c\\Tensorflow\\workspace\\annotations\\val.record\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jtorn\\miniconda3\\envs\\ray_c\\lib\\site-packages\\google\\auth\\crypt\\_cryptography_rsa.py:22: CryptographyDeprecationWarning: Python 3.6 is no longer supported by the Python core team. Therefore, support for it is deprecated in cryptography. The next release of cryptography (40.0) will be the last to support Python 3.6.\n",
      "  import cryptography.exceptions\n"
     ]
    }
   ],
   "source": [
    "# For XML Bounding Boxes\n",
    "from main import files, paths\n",
    "import os \n",
    "\n",
    "train_cmd = f\"\"\"python {files[\"TF_RECORD_SCRIPT\"]}\n",
    "        -x=\"{os.path.abspath(os.path.join(paths['IMAGE_PATH'], 'augmented'))}\"\n",
    "        -l=\"{os.path.abspath(files['LABEL_MAP'])}\"\n",
    "        -o=\"{os.path.abspath(os.path.join(paths['ANNOTATION_PATH'], 'train.record'))}\"\n",
    "        \"\"\"\n",
    "\n",
    "train_cmd = \" \".join([s.strip() for s in str(train_cmd).split()])\n",
    "\n",
    "!{train_cmd}\n",
    "\n",
    "val_cmd = f\"\"\"python {files[\"TF_RECORD_SCRIPT\"]}\n",
    "        -x=\"{os.path.abspath(os.path.join(paths['IMAGE_PATH'], 'val'))}\"\n",
    "        -l=\"{os.path.abspath(files['LABEL_MAP'])}\"\n",
    "        -o=\"{os.path.abspath(os.path.join(paths['ANNOTATION_PATH'], 'val.record'))}\"\n",
    "        \"\"\"\n",
    "\n",
    "val_cmd = \" \".join([s.strip() for s in str(val_cmd).split()])\n",
    "\n",
    "!{val_cmd}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from main import paths, files\n",
    "\n",
    "optimized_ckpt = None\n",
    "# optimized_ckpt = os.path.join(paths['CHECKPOINT_PATH'], \"export\", \"checkpoint\")\n",
    "optimized_config = None\n",
    "# optimized_config = os.path.join(\n",
    "    # paths['CHECKPOINT_PATH'], \"export\", \"pipeline.config\")\n",
    "\n",
    "TRAINING_SCRIPT = os.path.join(\n",
    "    paths['APIMODEL_PATH'], 'research', 'object_detection', 'model_main_tf2.py')\n",
    "\n",
    "steps = 4000\n",
    "\n",
    "command = \"python {} --model_dir={} --pipeline_config_path={} --num_train_steps={}\".format(\n",
    "    TRAINING_SCRIPT, optimized_ckpt or paths['CHECKPOINT_PATH'], optimized_config or files['PIPELINE_CONFIG'], steps)\n",
    "\n",
    "print(command)\n",
    "\n",
    "#!{command}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obtain metrics (loss, precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from main import paths, files\n",
    "\n",
    "TRAINING_SCRIPT = os.path.join(paths['APIMODEL_PATH'], 'research', 'object_detection', 'model_main_tf2.py')\n",
    "\n",
    "command = \"python {} --model_dir={} --pipeline_config_path={} --checkpoint_dir={}\".format(TRAINING_SCRIPT, paths['CHECKPOINT_PATH'], files['PIPELINE_CONFIG'], paths['CHECKPOINT_PATH'])\n",
    "\n",
    "print(command)\n",
    "\n",
    "# !{command}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze metrics with Tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensorboard --logdir=Tensorflow\\workspace\\models\\model\\eval\n",
      "Going to be ready on => http://localhost:6006/\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from main import paths\n",
    "\n",
    "host_url = \"http://localhost:6006/\"\n",
    "\n",
    "metrics_type = \"eval\" # train - eval\n",
    "\n",
    "log_dir = os.path.join(paths[\"CHECKPOINT_PATH\"], metrics_type)\n",
    "\n",
    "command = f\"tensorboard --logdir={log_dir}\"\n",
    "\n",
    "print(command)\n",
    "print(f\"Going to be ready on => {host_url}\")\n",
    "# !{command}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from main import paths, files\n",
    "\n",
    "FREEZE_SCRIPT = os.path.join(paths['APIMODEL_PATH'], 'research', 'object_detection', 'export_tflite_graph_tf2.py ')\n",
    "# command = \"python {} --input_type=image_tensor --pipeline_config_path={} --trained_checkpoint_dir={} --output_directory={}\".format(FREEZE_SCRIPT ,files['PIPELINE_CONFIG'], paths['CHECKPOINT_PATH'], paths['OUTPUT_PATH'])\n",
    "command = \"python {} --pipeline_config_path={} --trained_checkpoint_dir={} --output_directory={}\".format(FREEZE_SCRIPT ,files['PIPELINE_CONFIG'], paths['CHECKPOINT_PATH'], paths['OUTPUT_PATH'])\n",
    "\n",
    "print(command)\n",
    "\n",
    "!{command}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimizing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from main import paths\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "optimizer_images = os.path.join(paths[\"IMAGE_PATH\"], \"to_optimize_model\")\n",
    "\n",
    "# TODO: Make this work XD\n",
    "def representative_dataset_gen():\n",
    "  for _ in range(1, 5):\n",
    "    # Get sample input data as a numpy array in a method of your choosing.\n",
    "    image_path = os.path.join(optimizer_images, f'optimize ({_}).jpg')\n",
    "\n",
    "    img = cv2.imread(image_path)\n",
    "\n",
    "    if(img is None):\n",
    "        continue\n",
    "\n",
    "    print(f\"IMAGE => {image_path}\", img.size)   \n",
    "\n",
    "    img = cv2.imread(image_path)\n",
    "\n",
    "    image_np = np.array(img)\n",
    "\n",
    "    input_tensor = tf.convert_to_tensor(np.expand_dims(image_np, 0), dtype=tf.float32)\n",
    "\n",
    "    yield [input_tensor]\n",
    "\n",
    "converter = tf.lite.TFLiteConverter.from_saved_model(os.path.join(paths['OUTPUT_PATH'], \"saved_model\"))\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "# converter.representative_dataset = representative_dataset_gen\n",
    "\n",
    "tflite_quant_model = converter.convert()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sd_ckpt_name = \"urpm-inpainting.safetensors [b897946c3d]\"\n",
    "\n",
    "image_name = \"14.png\"\n",
    "\n",
    "text_prompt = \"\"\n",
    "negative_prompt = \"\"\n",
    "steps = 28\n",
    "fill_mode = \"original\"\n",
    "output_dir = \"out\"\n",
    "\n",
    "target_image_path = \"C:\\\\Users\\\\jtorn\\\\Desktop\\\\Dev\\\\Redes neuronales e AI\\\\ray_c\\\\Tensorflow\\\\workspace\\\\images\\\\test\\\\\" + image_name\n",
    "\n",
    "command = f\"\"\"python src/inpaint_regression.py \n",
    "            --sd_ckpt_name=\"{sd_ckpt_name}\"\n",
    "            --image_path=\"{target_image_path}\"\n",
    "            --text_prompt=\"{text_prompt}\"\n",
    "            --negative_prompt=\"{negative_prompt}\"\n",
    "            --output_dir=\"{output_dir}\"\n",
    "            \"\"\"\n",
    "\n",
    "command = \" \".join([s.strip() for s in str(command).split()])\n",
    "\n",
    "print(command)\n",
    "\n",
    "# !{command}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8aaca59d7360797302526982e45a61f547d6a80c62c514210b9174e3bedf312e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
